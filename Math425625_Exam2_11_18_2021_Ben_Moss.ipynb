{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exam2: MATH 425/625 Numerical Analysis**\n",
    "\n",
    "**Ben Moss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Consider the following formula for approximating the the second derivative:\n",
    "\n",
    "$$\n",
    "f^{\\prime\\prime}(x_0) = \\dfrac{f(x_0-h) - 2f(x_0) + f(x_0+h)}{h^2} - \\dfrac{h^2}{12}f^{(4)}(\\xi_0).\n",
    "$$\n",
    "Suppose that in evaluating $f(x_0-h)$, $f(x_0)$, and  $f(x_0 + h)$, we encounter round-off errors $e(x_0 - h)$, $e(x_0)$, and $e(x_0 + h)$. Assuming that the round-off errors are bounded by some number $\\epsilon > 0$ and that the 4th derivative of $f$ is bounded by a number $M > 0$, in the interval $[x_0 - h, x_0 + h]$, analyze the round-off error in approximating $f^{\\prime\\prime}(x_0)$ and derive an upper bound. \n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Suppose that in evaluating $f(x_0 - h)$, $f(x_0)$, and $f(x_0 + h)$, we encounter round-off errors $e(x_0 - h)$, e(x_0) and $e(x_0 + h).$ Then our computations actually use the values $\\tilde{f}(x_0 - h)$, $\\tilde{f}(x_0)$ and $\\tilde{f}(x_0 + h)$ which are related to the true values $f(x_0 - h)$, $f(x_0)$, and $f(x_0 + h)$ by\n",
    "$$f(x_0 - h)=\\tilde{f}(x_0 - h)+e(x_0 - h)$$\n",
    "$$2f(x_0)=2\\tilde{f}(x_0)+e(x_0)$$\n",
    "$$f(x_0 + h)=\\tilde{f}(x_0 + h)+e(x_0 + h).$$ \n",
    "\n",
    "The total error in the approximation, \n",
    "\n",
    "$$f''(x_0)- \\dfrac{\\tilde{f}(x_0 - h)-2\\tilde{f}(x_0)-\\tilde{f}(x_0 + h)}{h^2}=\\dfrac{e(x_0-h)-e(x_0)-e(x_0+h)}{h^2}-\\dfrac{h^2}{12}f^{(4)}(\\xi_0),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is due both to round-off error, the first part, and to truncation error. If we assume that the round-off errors $e(x_{0}\\pm\\,h)$ and $e(x_{0})$ are bounded by some number $\\epsilon>0$ and that the fourth derivative of $f$ is bounded by a number $M>0$ then "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\bigg\\lvert f''(x_0)- \\dfrac{\\tilde{f}(x_0 - h)-2\\tilde{f}(x_0)-\\tilde{f}(x_0 + h)}{h^2} \\bigg\\rvert\\leq \\bigg\\lvert\\dfrac{\\epsilon}{h^2}-\\dfrac{f^{(4)}(\\xi_0)}{12}h^2\\bigg\\rvert $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which in turn yields\n",
    "\n",
    "$$\\bigg\\lvert f''(x_0)- \\dfrac{\\tilde{f}(x_0 - h)-2\\tilde{f}(x_0)-\\tilde{f}(x_0 + h)}{h^2} \\bigg\\rvert\\leq \n",
    "\\dfrac{\\epsilon}{h^2}+\\dfrac{f^{(4)}(\\xi_0)}{12}h^2 \\leq \\dfrac{\\epsilon}{h^2} + \\dfrac{M}{12}h^2 .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our upper bound and our final answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 2:** A natural cubic spline $S$ on $[0,2]$ is defined by\n",
    "\\begin{align*}\n",
    "S(x) &= S_0(x) = 1 + B(x-1) - D(x-1)^3, 1 \\leq x < 2 \\\\\n",
    "S(x) &= S_1(x) = 1 + b(x-2) - \\frac{3}{4}(x-2)^2 + d(x-2)^3,  2 \\leq x \\leq 3\n",
    "\\end{align*} \n",
    "If $S$ interpolates the data $(1,1)$, $(2,1)$, $(3,0)$, find $B$, $D$, $b$, $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "x_grid = np.arange(1,4,1)\n",
    "print(x_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "y_grid = [1, 1, 0]\n",
    "print(y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = x_grid[0] - x_grid[1]\n",
    "h1 = x_grid[1] - x_grid[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(h0)\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASpline = np.array([[1,0],\n",
    "                  [0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(ASpline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "Yvec = np.array([[0],  \n",
    "                 [0]])\n",
    "print(Yvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = \n",
      " [[0.]\n",
      " [0.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvalues = linalg.solve(ASpline, Yvec)\n",
    "print('c = \\n', cvalues, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CubicSpline(x_grid, y_grid, bc_type = 'natural')\n",
    "\n",
    "# S1 Polynomial coefficients\n",
    "a0 = cs.c.item(3,0)\n",
    "b0 = cs.c.item(2,0)\n",
    "c0 = cs.c.item(1,0)\n",
    "d0 = cs.c.item(0,0)\n",
    "\n",
    "# S2 Polynomial coefficients\n",
    "a1 = cs.c.item(3,1)\n",
    "b1 = cs.c.item(2,1)\n",
    "c1 = cs.c.item(1,1)\n",
    "d1 = cs.c.item(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0(1<=x<2) =  1.0  +  0.25000000000000006 (x-1) +  0.0 (x-1)^2  +  -0.25000000000000006 (x-1)^3\n",
      "S1(2<= x<=3) =  1.0  +  -0.5000000000000001 (x-2) +  -0.7499999999999999 (x-2)^2  +  0.25 (x-2)^3\n"
     ]
    }
   ],
   "source": [
    "# Print polynomial equations for different x regions\n",
    "print('S0(1<=x<2) = ', a0, ' + ', b0, '(x-1) + ', c0, '(x-1)^2  + ', d0, '(x-1)^3')\n",
    "print('S1(2<= x<=3) = ', a1, ' + ', b1, '(x-2) + ', c1, '(x-2)^2  + ', d1, '(x-2)^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, our coefficients are $B=D=d=\\dfrac{1}{4}$ and $b=-\\dfrac{1}{2}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily verify this by hand, we have \n",
    "$$S_{0}(1)=1+0.25(1-1)-0.25(1-1)^{3}=0,$$\n",
    "$$S_{1}(2)=1-0.5(2-2)-0.75(2-2)^2+0.25(2-2)^3=1,$$\n",
    "$$S_{1}(3)=1-0.5(3-2)-0.75(3-2)^2+0.25(3-2)^3=0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the result holds and these coefficients are the final answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question 3:** Use the `TensorFlow` library to implement the *modified* Newton's method for finding the non-simple root (i.e., multiplicity $m > 1$) of $f(x) = e^x - x - 1$. You should use the build in functions for automatic differentiation in order to compute the derivatives. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** We begin by implementing Newton's modified algorithm to use as a basis for our code. We have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnewton(f,Df,DDf,x0,epsilon,max_iter):\n",
    "    '''Approximate solution of f(x)=0 utilizing Newton's modified method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        Function for which we are searching for a solution f(x)=0.\n",
    "    Df : function\n",
    "        Derivative of f(x).\n",
    "    DDf: function\n",
    "        Derivative of Df\n",
    "    x0 : number\n",
    "        Initial guess for a solution f(x)=0.\n",
    "    epsilon : number\n",
    "        Stopping criteria is abs(f(x)) < epsilon.\n",
    "    max_iter : integer\n",
    "        Maximum number of iterations of Newton's method.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xn : number\n",
    "        Implement Newton's modified algorithm: compute the linear approximation\n",
    "        of f(x) at xn and find x intercept by the formula\n",
    "            x = xn - f(xn)/Df(xn)\n",
    "        Continue until abs(f(xn)) < epsilon and return xn.\n",
    "        If Df(xn) == 0, return None. If the number of iterations\n",
    "        exceeds max_iter, then return None.\n",
    "        '''\n",
    "    xn = x0\n",
    "    for n in range(0,max_iter):\n",
    "        fxn = f(xn)\n",
    "        if abs(fxn) < epsilon:\n",
    "            print('Found solution after',n,'iterations.')\n",
    "            return xn\n",
    "        Dfxn = Df(xn)\n",
    "        if Dfxn == 0:\n",
    "            print('Zero derivative. No solution found.')\n",
    "            return None\n",
    "        DDfxn = DDf(xn)\n",
    "        if DDfxn == 0:\n",
    "            print('Zero second derivative. No solution found.')\n",
    "            return None\n",
    "        xn = xn - (fxn*Dfxn)/(Dfxn**2-(fxn*DDfxn))\n",
    "    print('Exceeded maximum iterations. No solution found.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found solution after 3 iterations.\n",
      "-1.1890183808588653e-05\n"
     ]
    }
   ],
   "source": [
    "p = lambda x: math.exp(x) - x - 1\n",
    "Dp = lambda x: math.exp(x) - 1\n",
    "DDp = lambda x: math.exp(x)\n",
    "approx = mnewton(p,Dp,DDp,1,1e-10,10)\n",
    "print(approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must use TensorFlow to define a few variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable((0.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y = tf.exp(x)-x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape2:\n",
    "    y_2 = tf.exp(x)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p2 = tape2.gradient(y_2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape3:\n",
    "    y_3 = tf.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p3 = tape3.gradient(y_3, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p3.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found the local minimum of $f(x)=e^{x}-x-1$ is $f'(0)=e^{0}-1=0$, and thus $x=0$ is a local minimum of this function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observation, since $f(x)=e^{x}-x-1$ is strictly decreasing over the interval $(-\\infty,0]$ as $x\\rightarrow0$ and $f(x)=e^{x}-x-1$ is strictly increasing over the interval $[0,\\infty)$ as $x\\rightarrow\\infty$ we know that $x=0$ is also a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed with the Newton's modified method with TensorFlow. We have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnewton2(f,Df,DDf,x0,epsilon,max_iter):\n",
    "    '''Approximate solution of f(x)=0 utilizing Newton's modified method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        Function for which we are searching for a solution f(x)=0.\n",
    "    Df : function\n",
    "        Derivative of f(x).\n",
    "    DDf: function\n",
    "        Derivative of Df\n",
    "    x0 : number\n",
    "        Initial guess for a solution f(x)=0.\n",
    "    epsilon : number\n",
    "        Stopping criteria is abs(f(x)) < epsilon.\n",
    "    max_iter : integer\n",
    "        Maximum number of iterations of Newton's method.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xn : number\n",
    "        Implement Newton's modified algorithm: compute the linear approximation\n",
    "        of f(x) at xn and find x intercept by the formula\n",
    "            x = xn - f(xn)/Df(xn)\n",
    "        Continue until abs(f(xn)) < epsilon and return xn.\n",
    "        If Df(xn) == 0, return None. If the number of iterations\n",
    "        exceeds max_iter, then return None.\n",
    "        '''\n",
    "    xn = x0\n",
    "    for n in range(0,max_iter):\n",
    "        fxn = y\n",
    "        if abs(fxn) < epsilon:\n",
    "            print('Found solution after',n+1,'iteration.')\n",
    "            return xn\n",
    "        Dfxn = y_p\n",
    "        if Dfxn == 0:\n",
    "            print('Zero derivative. No solution found.')\n",
    "            return None\n",
    "        DDfxn = y_p2\n",
    "        if DDfxn == 0:\n",
    "            print('Zero second derivative. No solution found.')\n",
    "            return None\n",
    "        xn = xn - (fxn*Dfxn)/(Dfxn**2-(fxn*DDfxn))\n",
    "    print('Exceeded maximum iterations. No solution found.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found solution after 1 iteration.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "p = lambda x: y\n",
    "Dp = lambda x: y_p\n",
    "DDp = lambda x: y_p2\n",
    "approx = mnewton2(y,y_p,y_p2,0,1e-10,10)\n",
    "print(approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution was found after one iteration because differentiation a single time is necessary to solve for the $0$ of the function. Therefore, $0$ is the solution to the zero of our function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 4:** (Graduate Students): Suppose that $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ is given by $f(x) = x^T Q X$, where $Q$ is an $n \\times n$ (symmetric) positive semidefinite matrix. Show that $f$ is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof:** Given $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ is defined by $f(x) = X^T Q X$, where $Q$ is an $n \\times n$ (symmetric) positive semidefinite matrix, we will show that $f$ is convex. \n",
    "\n",
    "We will proceed directly by showing that\n",
    "$$f(x_{2}+t(x_{1}-x_{2}))-tf(x_{1})-(1-t)f(x_{2})\\leq0$$ \n",
    "\n",
    "for all $x_{1},\\,x_{2}\\in \\mathbb{R}^{n}$ with $x_{1}\\neq\\,x_{2}$ and for all $t\\in[0,1].$ If this parameterized inequality holds then this will prove $f$ is convex. We proceed with direct calculation. We have that the above inequality is equal to the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "(x_{2}^{T}+tx_{1}^{T}-tx_{2}^{T})(Qx_{2}+tQx_{1}-tQx_{2})-tx_{1}^{T}Qx_{1}-(1-t)x_{2}^{T}Qx_{2}&= \\\\\n",
    "x_{2}^{T}Qx_{2}+tx_{2}^{T}Qx_{1}-tx_{2}^{T}Qx_{2}+tx_{1}^{T}Qx_{2}+t^{2}x_{1}^{T}Qx_{1}-t^{2}x_{1}^{T}Qx_{2}-tx_{2}^{T}Qx_{2}-t^{2}x_{2}^{T}Qx_{1}+t^{2}x_{2}^{T}Qx_{2} \\\\\n",
    "-tx_{1}^{T}Qx_{1}-(1-t)x_{2}^{T}Qx_{2}&= \\\\\n",
    "(1-2t+t^2-1+t)x_{2}^{T}Qx_{2}+(t^2-t)x_{1}^{T}Qx_{1}+(t+t-t^2-t^2)x_{2}^{T}Qx_{1} &=\\\\\n",
    "(-2t+t^2+t)x_{2}^{T}Qx_{2}+(t^2-t)x_{1}^{T}Qx_{1}+(2t-2t^2)x_{2}^{T}Qx_{1} &=\\\\\n",
    "(t^2-t)x_{2}^{T}Qx_{2}-2(t^2-t)x_{2}^{T}Qx_{1}+(t^2-t)x_{1}^{T}Qx_{1} &= \\\\\n",
    "(t^2-t)\\cdot(x_{1}-x_{2})^{T}Q(x_{1}-x_{2}).&\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line $(t^2-t)\\cdot(x_{1}-x_{2})^{T}Q(x_{1}-x_{2})\\leq 0$ because $(t^2-t)\\leq0$ for all $t\\in[0,1]$ and thus the result follows. $\\blacksquare$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
